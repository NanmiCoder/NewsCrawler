# NewsCrawlerCollection

English Â· [ä¸­æ–‡](README.md)

A multi-platform news and content crawler collection, supporting both command-line and Web UI usage modes.

![Web UI](static/images/03_webui_en.png)

## ğŸ¯ Key Features

- **Multi-Platform Support** - 6+ mainstream news/content platforms (WeChat, Toutiao, Lenny, Naver, Detik, Quora)
- **Dual Usage Modes** - Supports both Python API calls and Web UI operations
- **Unified Data Format** - All platforms output standardized JSON format
- **Modern Tooling** - Uses uv package manager for lightning-fast dependency installation




## ğŸ“¦ Supported Platforms

### News/Content Platforms
| Platform | URL Example | Status |
|----------|-------------|--------|
| WeChat Official Accounts | `mp.weixin.qq.com` | âœ… |
| Toutiao | `toutiao.com` | âœ… |
| Lenny's Newsletter | `lennysnewsletter.com` | âœ… |
| Naver Blog | `blog.naver.com` | âœ… |
| Detik News | `detik.com` | âœ… |
| Quora | `quora.com` | âœ… |

### Stock Video Platforms
- Pexels, Pixabay, Coverr, Mixkit

---

## ğŸš€ Quick Start

### 1. Environment Setup

**Install uv (Python Package Manager)**

```bash
# macOS / Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# Windows
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"

# Or use pip
pip install uv
```

**Install Project**

```bash
# Clone the repository
git clone https://github.com/NanmiCoder/NewsCrawlerCollection.git
cd NewsCrawlerCollection

```

### 2. Usage Methods

#### Method 1: Web UI (Recommended, Ready to Use ğŸ‰)

**Start Backend Service**

```bash
cd news-extractor-ui/backend
uv sync          # Install backend dependencies
uv run run.py    # Start backend (port 8000)
```

**Start Frontend Service** (new terminal)

```bash
cd news-extractor-ui/frontend
npm install        # Install frontend dependencies
npm run dev        # Start frontend (port 3000)
```

**Access Application**

Open your browser and visit `http://localhost:3000` to extract news content through the visual interface.

#### Method 2: Python API Calls (Suitable for Automation Integration)

```python
from news_crawler.wechat_news import WeChatNewsCrawler
from news_crawler.toutiao_news import ToutiaoNewsCrawler

# WeChat Official Account
wechat_url = "https://mp.weixin.qq.com/s/xxxxxx"
crawler = WeChatNewsCrawler(wechat_url)
result = crawler.run()

# Toutiao
toutiao_url = "https://www.toutiao.com/article/xxxxxx"
crawler = ToutiaoNewsCrawler(toutiao_url)
result = crawler.run()
```

Run example code:
```bash
# View complete examples
cat call_example.py

# Run examples
uv run call_example.py
```

---

## ğŸ“¦ Data Output Format

All crawlers output a unified JSON format, saved in the `data/` directory:

```json
{
  "title": "Article Title",
  "news_url": "Original URL",
  "news_id": "Article ID",
  "meta_info": {
    "author_name": "Author",
    "publish_time": "Publish Time"
  },
  "contents": [
    {"type": "text", "content": "Paragraph content", "desc": ""},
    {"type": "image", "content": "Image URL", "desc": ""}
  ],
  "texts": ["Plain text content..."],
  "images": ["Image URLs..."],
  "videos": ["Video URLs..."]
}
```

---

## ğŸ“ Project Structure

```
NewsCrawlerCollection/
â”‚
â”œâ”€â”€ news_crawler/              # News crawler modules (Core)
â”‚   â”œâ”€â”€ wechat_news/          # WeChat Official Accounts
â”‚   â”œâ”€â”€ toutiao_news/         # Toutiao
â”‚   â”œâ”€â”€ lennysnewsletter/     # Lenny's Newsletter
â”‚   â”œâ”€â”€ naver_news/           # Naver Blog
â”‚   â”œâ”€â”€ detik_news/           # Detik News
â”‚   â””â”€â”€ quora/                # Quora
â”‚
â”œâ”€â”€ news-extractor-ui/         # Web UI Application
â”‚   â”œâ”€â”€ backend/              # FastAPI Backend
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ api/          # API Routes
â”‚   â”‚   â”‚   â”œâ”€â”€ adapters/     # Crawler Adapters
â”‚   â”‚   â”‚   â””â”€â”€ services/     # Business Logic
â”‚   â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â”‚   â””â”€â”€ run.py
â”‚   â”‚
â”‚   â””â”€â”€ frontend/             # Vue 3 Frontend
â”‚       â”œâ”€â”€ src/
â”‚       â”‚   â”œâ”€â”€ components/   # UI Components
â”‚       â”‚   â”œâ”€â”€ services/     # API Services
â”‚       â”‚   â””â”€â”€ types/        # TypeScript Types
â”‚       â”œâ”€â”€ package.json
â”‚       â””â”€â”€ vite.config.ts
â”‚
â”œâ”€â”€ video_crawler/            # Video Downloader Modules
â”‚   â”œâ”€â”€ pexel/               # Pexels
â”‚   â”œâ”€â”€ pixabay/             # Pixabay
â”‚   â”œâ”€â”€ cover_video/         # Coverr
â”‚   â””â”€â”€ mixkit_video/        # Mixkit
â”‚
â”œâ”€â”€ libs/                     # Utility Libraries
â”‚   â”œâ”€â”€ playwright_driver.py # Browser Automation
â”‚   â””â”€â”€ drissionpage_driver.py
â”‚
â”œâ”€â”€ data/                     # Output Data Directory
â”œâ”€â”€ call_example.py          # Usage Example Code
â”œâ”€â”€ pyproject.toml           # Project Configuration (uv)
â””â”€â”€ README.md
```

---

## ğŸ”§ Technology Stack

### Backend
- **Python 3.8+**
- **FastAPI** - Modern web framework
- **Pydantic** - Data validation
- **curl_cffi / requests** - HTTP requests
- **parsel** - HTML parsing

### Frontend
- **Vue 3** - Progressive framework
- **TypeScript** - Type safety
- **Vite** - Build tool

### Tools
- **uv** - Lightning-fast Python package manager
- **Playwright** - Browser automation (optional)

---

## âš ï¸ Important Notes

1. **Legal Compliance**
   - For educational and research purposes only, commercial use is prohibited
   - Comply with target websites' robots.txt and terms of service
   - Control request frequency to avoid server stress

2. **Cookie Management**
   - Default headers may expire; use Playwright to auto-fetch when issues occur
   - Recommend updating cookies regularly

3. **Data Usage**
   - Respect content copyrights; do not use for illegal purposes
   - Collected data should only be used for personal learning and research

---

## ğŸ“ Disclaimer

**All content in this repository is for learning and reference purposes only. Commercial use is strictly prohibited.**

- No person or organization may use the content of this repository for illegal purposes or to infringe on the legitimate rights and interests of others
- The web scraping techniques involved in this repository are for learning and research only, and must not be used for large-scale crawling or other illegal activities on other platforms
- This repository assumes no responsibility for any legal liability arising from the use of its content
- By using the content of this repository, you agree to all terms and conditions of this disclaimer

---

## ğŸ¤ Contributing

Issues and Pull Requests are welcome to improve the project!

## ğŸ“„ License

This project is for learning and research purposes only.

---

## ğŸ”— Related Links

- [uv - Python Package Manager](https://github.com/astral-sh/uv)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Vue 3 Documentation](https://vuejs.org/)
